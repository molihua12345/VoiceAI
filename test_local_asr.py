"""
æœ¬åœ°è¯­éŸ³è½¬æ–‡å­—æµ‹è¯•è„šæœ¬
æµ‹è¯•éŸ³é¢‘é‡‡é›† -> VAD -> ASR æµç¨‹ï¼Œæ— éœ€äº‘ç«¯æœåŠ¡
"""

import numpy as np
import logging
import time
import sys
import os

# è®¾ç½®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from local_client.audio_buffer import AudioCapture
from local_client.vad_module import VADProcessor
from local_client.asr_engine import SenseVoiceASR, StreamingASR

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class LocalASRTest:
    """æœ¬åœ° ASR æµ‹è¯•"""
    
    def __init__(self):
        self.audio_capture = None
        self.vad = None
        self.asr = None
        self.streaming_asr = None
        
        # è¯­éŸ³ç¼“å†²
        self.speech_buffer = []
        self.is_speaking = False
        
    def init_modules(self):
        """åˆå§‹åŒ–æ¨¡å—"""
        print("\n" + "="*50)
        print("  åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«æ¨¡å—...")
        print("="*50 + "\n")
        
        # 1. åˆå§‹åŒ–éŸ³é¢‘é‡‡é›†
        print("[1/3] åˆå§‹åŒ–éŸ³é¢‘é‡‡é›†...")
        self.audio_capture = AudioCapture()
        print("      éŸ³é¢‘é‡‡é›†å°±ç»ª âœ“")
        
        # 2. åˆå§‹åŒ– VAD
        print("[2/3] åˆå§‹åŒ– VAD (Silero-VAD)...")
        self.vad = VADProcessor(
            on_speech_start=self._on_speech_start,
            on_speech_end=self._on_speech_end,
            use_gpu=True
        )
        print("      VAD å°±ç»ª âœ“")
        
        # 3. åˆå§‹åŒ– ASR
        print("[3/3] åˆå§‹åŒ– ASR (SenseVoiceSmall)...")
        print("      é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        self.asr = SenseVoiceASR(use_gpu=True)
        self.streaming_asr = StreamingASR(
            asr_engine=self.asr,
            on_partial_result=self._on_partial_result,
            on_final_result=self._on_final_result
        )
        print("      ASR å°±ç»ª âœ“")
        
        print("\næ‰€æœ‰æ¨¡å—åˆå§‹åŒ–å®Œæˆï¼\n")
    
    def _on_audio_frame(self, frame: np.ndarray):
        """éŸ³é¢‘å¸§å›è°ƒ"""
        # VAD å¤„ç†
        result = self.vad.process_frame(frame)
        
        # å¦‚æœæ­£åœ¨è¯´è¯ï¼Œæ”¶é›†éŸ³é¢‘
        if result.is_speech or self.is_speaking:
            self.speech_buffer.append(frame.copy())
    
    def _on_speech_start(self):
        """è¯­éŸ³å¼€å§‹"""
        self.is_speaking = True
        self.speech_buffer = []
        # è·å–é¢„ç¼“å†²
        pre_buffer = self.audio_capture.get_pre_buffer()
        if len(pre_buffer) > 0:
            self.speech_buffer.append(pre_buffer)
        print("\nğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ­£åœ¨å½•éŸ³...", end='', flush=True)
    
    def _on_speech_end(self):
        """è¯­éŸ³ç»“æŸ"""
        self.is_speaking = False
        print(" å®Œæˆ")
        
        if self.speech_buffer:
            # åˆå¹¶éŸ³é¢‘
            audio = np.concatenate(self.speech_buffer)
            duration = len(audio) / 16000
            print(f"   å½•éŸ³æ—¶é•¿: {duration:.1f}ç§’")
            
            # æ‰§è¡Œè¯†åˆ«
            print("   æ­£åœ¨è¯†åˆ«...", end='', flush=True)
            start_time = time.time()
            result = self.asr.transcribe(audio)
            latency = (time.time() - start_time) * 1000
            
            print(f" å®Œæˆ ({latency:.0f}ms)")
            print(f"\n   ğŸ“ è¯†åˆ«ç»“æœ: {result.text}\n")
        
        self.speech_buffer = []
    
    def _on_partial_result(self, text: str):
        """éƒ¨åˆ†è¯†åˆ«ç»“æœ"""
        print(f"\r   [éƒ¨åˆ†] {text}", end='', flush=True)
    
    def _on_final_result(self, text: str):
        """æœ€ç»ˆè¯†åˆ«ç»“æœ"""
        print(f"\n   [æœ€ç»ˆ] {text}")
    
    def run(self):
        """è¿è¡Œæµ‹è¯•"""
        try:
            self.init_modules()
            
            print("="*50)
            print("  è¯­éŸ³è½¬æ–‡å­—æµ‹è¯•")
            print("="*50)
            print("\nè¯´è¯å¼€å§‹å½•éŸ³ï¼Œåœé¡¿åè‡ªåŠ¨è¯†åˆ«")
            print("æŒ‰ Ctrl+C é€€å‡º\n")
            print("-"*50)
            
            # å¼€å§‹éŸ³é¢‘é‡‡é›†
            self.audio_capture.start(self._on_audio_frame)
            
            # ä¸»å¾ªç¯
            while True:
                time.sleep(0.1)
                
        except KeyboardInterrupt:
            print("\n\næ­£åœ¨å…³é—­...")
        finally:
            if self.audio_capture:
                self.audio_capture.stop()
            print("æµ‹è¯•ç»“æŸ")


def main():
    test = LocalASRTest()
    test.run()


if __name__ == "__main__":
    main()
